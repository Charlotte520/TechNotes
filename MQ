《kafka》
8.集群参数
broker:log.dirs。可挂载到不同物理磁盘，提升读写性能，故障转移（1.1前任一磁盘挂掉会关闭整个broker，1.1后将坏磁盘数据自动转移到其他正常磁盘，broker正常）。zookeeper.connect。listeners：外部连接者通过什么协议访问指定host:port的kafka服务。auto.create.topic.enable:false。若producer启动时写错了topic，会自动创建。auto.leader.rebalance.enable=false。
topic：保留时间，retention.ms：默认7d。retention.bytes:最大磁盘。max.message.bytes：能接收的最大消息。
jvm：heap 6GB。gc：若cpu充足用cms，否则用吞吐量收集器。jdk8用g1，full gc少。
os：fd限制，ulimit -n。swap：较小值，若为0,物理内存耗尽时oom，os会随机选一个进程kill，若设为较小值，容易观测到broker性能急剧下降。提交时间/flush落盘时间：数据写入os page cache即可认为成功，根据LRU定期（5s）写入磁盘，但flush前的数据可能丢失，由于有多副本，可以容忍。

9.producer partition
负载均衡，高伸缩性，partition内部消息顺序性。
分区策略：partition.class，实现Partitioner接口，partition(),close()。轮询；key-ordering，按key.hashcode%#partitions；根据ip的geo-location。

10. producer compression
message：v1每条msg都有CRC校验，v2为msg set进行CRC校验。V1每条消息压缩，v2对整个msg set压缩，效率更高。
producer配置：compression.type，启用对应压缩算法，类型记录到msg set中。节省网络带宽和broker磁盘，在consumer解压缩。但若broker和producer压缩算法不同，broker会先解压缩，再用自己的压缩算法重新压缩。或broker发生消息格式转化，也会解压缩，且丧失0copy特性。

11.无消息丢失
已提交消息：若干broker成功收到并写入log。用producer.send(msg，callback)带回调的异步发送，acks=all，所有replica都收到消息才成功。retries自动重试设置较大值。unclean.leader.election.enable=false，当leader挂掉，落后太多的follower不能成为leader。replication.factor>=3。min.insync.replicas>1，消息至少写入几个replica。 enable.auto.commit=false


12.producer 拦截器
interceptor.classes：实现ProducerInterceptor接口，onSend()发送前调用,onAck()发送成功或失败调用，在callback前，与onsend不在同一线程，注意共享变量的线程安全问题。ConsumerInterceptor接口，onConsume()消息处理前,onCommit()提交offset后。

13.producer tcp
tcp多路复用请求：将多个数据流合并到底层单一物理连接。即在一条物理连接上创建多个虚拟连接，每个连接负责各自对应的数据流。
建立连接：new KafkaProducer()时，后台创建sender线程，建立与bootstrap.servers中配置的broker的连接。一般配3~4台，连接到任一broker后可得到整个集群的broker信息。再向某台broker发metadata请求。若发现与某些broker当前没有建立连接，则创建。send()时，若发现目标broker没有建立连接，创建。metadata.max.age.ms定期更新meta。
关闭连接：主动关闭producer.close()；被动由broker关闭，connections.max.idle.ms=9min，若9min内该conn没有数据，则broker端关闭。producer会产生close_wait连接，无法显式观测到连接中断。

14.producer 幂等 & 事务
默认at least once。
幂等producer：props.put("enable.idempotentce",true)。broker多保留一些字段，当收到有相同字段的消息时，自动去重。只能保证partition内去重，单session内去重，重启producer会失效。
多partition、多session去重：事务。read commited级别，可将多消息原子写入多个partition，且consumer只能看到commit成功的消息。设置enable.idempotentce，和producer transactional.id。producer.initTransaction(); producer.beginTransaction(); producer.send(msg); ... producer.commitTransaction();/abort。consumer端：read_commited。broker通过2pc，通过transactional coordinator完成。性能问题。

15.consumer group
可扩展、容错的consumer机制，有多个consumer实例，可多进程/多线程。#consumer=#partition。

16. _consumer_offsets topic
老版本consumer offste提交到zk。但zk不适合高频写。=》存到offset topic。消息格式：key：<consumer_groupid ,topic,partition>，value：offset，时间戳，用户自定义数据等。可用于删除过期offst等操作。其他消息：保存consumer group信息的消息（注册consumer group时）；删除group过期offset的消息，或删除group的消息（delete mark，当consumer group下所有consumer都停止了，且offst数据已被删除，kafka写入该消息，彻底删除该group的消息）。
创建：集群启动第一个consumer程序时。分区数：offsets.topic.num.partitions=50，replica=3。
删除过期offset：compaction。后台线程log cleaner，定期扫描log的所有消息，同一key的不同消息，取发送时间最新的，其他为过期，删除。

17.consumer group rebalance
一个group下所有consumer，通过coordinator，就如何消费partition达成共识。此过程中，所有consumer都不能消费。
coordinator：每个broker都有coordinator组件，为consumer group执行rebalance，提供offset管理，group member管理。consumer commit offset是通过coordinator所在broker提交。consumer启动时向coordinator broker发请求，进行注册、管理member等meta。consumer group如何确定coordinator所在broker？先根据groupid%50得到partitionid，找到该partition leader所在broker。
rebalance缺点：停止consumer；慢；不考虑局部性，效率低。Sticky assigner：尽可能保存之前分区方案。
rebalance时机：group member变化；topic变化；partition变化。=》后两者不可避免，如何避免member变化？启动一个group.id为当前group的consumer，发请求给coordinator，加入，rebalance。为了增加tps，不可避免。减少：consumer在session.timeout.ms=10s没有发送heartbeat给coordinator，发送间隔为heartbeat.interval.ms，一般timeout是interval>3倍。检查consumer是否因gc超时。


18.consumer offstet commit
记录下一条消息的offset。
enable.auto.commit=true，consumer后台自动提交，提交间隔：auto.commit.interval.ms,默认5s。在每次开始调用poll()时，先提交上次poll()的最新offset。可保证不丢，但可能重复：若两次commit间，发生rebalance。所有consumer从上次commit offset开始消费，则两次commit间的数据会重复。
手动提交：enable.auto.commit=false。且consumer.commitSync()，同步提交consumer.poll()得到的最新offset，阻塞直到broker返回结果。若有瞬时错误，会自动重试。consumer.commitAsync(offset，callbackhandler)异步commit，异常时不能重试。=》组合：先async提交避免阻塞，在consumer.close()前，sync commit保证offset正确。若一次poll很多消息，可在consume期间commit offset。

19.CommitFailedException
调用consumer.commitSync()时，1)若commit期间，consumer group开始rebalance，且将要commit的parition分配给其他consumer。2)consumer处理时间太长，耽误了poll()。=》增加max.poll.interval.ms，或减少每次poll的消息数max.poll.records，或缩短单条消息处理时间，或下游多线程加速消费（如何多线程commit？）。3)不同consumer group的group.id冲突




RabbitMQ：高并发、高吞吐、性能高；后台管理界面；集群化、高可用部署、消息高可靠；实践多、社区活跃。缺点：erlang开发，难改造。有broker的复杂路由：exchange：根据复杂的业务规则将msg路由到不同queue。queue：exchange向一个queue写msg，多个consumer消费该queue，但每条msg只能给一个consumer。pub/sub：每个consumer一个queue，绑定到exchange。若某consumer只消费某类数据，exchange可将带xx前缀的msg发到该queue。吞吐比kafka低一个数量级。适合不同业务系统要复杂消息路由的场景。eg.A发10条msg，3条给b，7条给c。
RocketMQ:高并发、高吞吐、分布式事务。
kafka：消息中间件的功能少，优化吞吐。适合高吞吐的日志采集、数据同步、实时计算，几十万/百万/s。结合storm、spark streaming等。有broker的暴力路由：生产消费模型用简单的数据流模型，producer向topic写数据，分成多个partition，消息发到某个partition。消费时，每条消息只发给consumer group中的一个consumer，即partition：consumer=*：1，形成queue。publish/subscribe模型：生产者的每条消息要让所有consumer消费，使每个consumer一个group，订阅相同topic。

引入原因：系统解耦；异步调用；流量削峰；实时计算
缺点：系统可用性降低；稳定性降低（丢数据、重复、下游宕机后消息堆积）；事务一致性。

1. kafka
如何实现每秒几十万的高并发写入？
页缓存+磁盘顺序写：每次收到数据，写入os page cache，再由os顺序写到disk。
0拷贝读：先看数据是否在os cache，若不在读磁盘后后放入os cache。再从os cache拷贝到kafka进程cache，再拷贝到socket cache，再发到网卡。多次拷贝，上下文切换。=》将fd拷贝到socket cache，将数据从os cache发到网卡。
如何保证数据不丢？
业务定义topic；topic可拆分为多个partition，分配到不同机器；每个partition多副本放在其他机器（1leader+多follower，主从复制，只写leader），防止宕机丢数据。
若数据写入leader，但还没同步到follower，leader宕机：每个partition至少有1个follower在isr列表；写入时，要求leader和至少一个follower写入成功，否则写入失败重试。
ISR：每个partition对应一个isr列表，包括leader+与leader同步的follower。若某follower没及时同步（如JVM GC等），out of sync，移出isr。
Producer ACK：0，只要prod发送成功就认为成功，即使没有在leader落盘,有可能丢。1,leader写入磁盘，不管其他follower有没有同步成功，就认为成功，默认。当leader挂掉，follower还没同步，可能丢。all，leader落盘，且ISR中的follower都同步成功才成功。若isr只有一个leader，没有follower仍可能丢。


2. 如何设计消息中间件
存储：内存 or 磁盘？先写内存做缓冲，每隔几秒刷入磁盘。磁盘文件拆分规则。磁盘文件meta：数据offset、id。数据量增大，分片，扩容。
某机器宕机后的数据丢失问题：多副本。
生产端ack：
消费端ack：手动。

3.RabbitMQ
需要配queue、message是否持久化：不保证完全不丢消息。接收到消息但还没持久化时，宕机则丢数据。=》事务消息（性能差）；轻量级的confirm。
消费者：与mq建立channel，根据自增的deliverytag ack。可批量ack。

2.MQ高可用
1) kv集群
封装mq client：连续10次retry都有异常报错、网络无法联通等，自动触发zk降级开关。
降级方案：redis队列替代queue。但不能写value过大的数据；不能往少数热点key持续写数据（kv集群通常用hash（key）分配到不同机器，热点key会导致某机器负载过大）=》根据消息量，在kv中划分上百个队列，对应上百个key。故障后对每个消息进行hash，均匀写入固定的kv队列。
下游mq client降级感知：
自动恢复：后台线程，每隔一段时间尝试给mq发消息看是否恢复。可发消息后自动关闭zk降级开关。向mq发消息，下游消费完kv消息后，切换到mq。
2) 异步转同步+限流+限制性丢弃流量
不写mq，直接调用流控集群的备用接口。若流量超过阈值，丢弃。丢弃策略：电商，仅选少量商家的全部丢弃，大部分全量保存。

3.KV高可用
临时扩容slave+内存分片存储+小时级数据粒度
报警后手动扩容n倍slave集群，流控集群按预设的hash算法分发数据。slave只存最近1h的数据。

4.实时计算链路
slave宕机，master感知，将计算任务重新分配到其他节点。master宕机，基于active-standby，自动切换主备。

《消息队列高手》
2.选型
rabbitmq：producer和queue之间有exchange，可灵活路由。对消息堆积支持不好；性能不佳，十几万/s；erlang。
rocketmq：java，性能、稳定性、可靠性好。ms级延迟，适合在线业务；几十万/s
kafka：java & scala；生态兼容性好；几十万/s；批量、异步处理；同步时延高，不适合在线业务。海量数据，收集log、监控、前端埋点。
pulsar：存储与计算分离

3.topic、queue


4.分布式事务：2pc，tcc，消息事务
创建订单，清理购物车：先开启mq事务，发半消息给mq；执行本地事务，创建订单；再提交/回滚mq事务。=》若最后一步失败，kafka抛异常，由业务重试或删除订单补偿。rocketmq：定期去producer反查消息事务对应的本地事务的状态，再决定对消息commit/rollback。本地事务需要提供反查api。
acid：a：本地事务和发消息是分离的操作。c：异步操作，只能最终一致。i：本地事务提交后，其他事务消息已经可见。d：若半消息存在内存，不满足。

5.不丢消息
检测丢失：1)分布式链路追踪：在服务调用网络间埋点，得到一次request处理的各服务调用链。google dapper  2)producer通过拦截器给msg带连续递增id，consumer检查id是否连续。kafka只能保证partition有序，各producer分别生成连续递增msg，且带producer id。consumer与partition一一对应检测。
生产阶段：发送时收到ack才能保证可靠，否则重试，再抛异常。同步：RecordMetaData d = producer.send(msg).get()，收到ack时get()才返回。异步：producer.send(msg,(d,exception)->{xxx}) 回调中检查发送结果。
存储阶段：若单节点broker，要将msg写入磁盘再返回ack。若多节点，至少发2个以上节点再返回ack。
消费阶段：msg处理完再commit

6.重复消息
kafka 事务、exactly once是为了配合streaming使用，与MQTT exactly once不同，传统分布式事务也不同。故kafka是MQTT的at least once。不做exactly once：影响性能，易堆积。
消费端幂等：
1)利用db唯一性约束（转账流水表：账单id+账户id，金额，对账单id+账户id建立unique index，消费时先插入db，若成功再消费），和任意支持insertIfNotExist操作的存储（如redis setnx）。
2)为更新数据设置前置条件。checkandput，即msg中带当前值，更新前先看db是否和当前值相等，相等才执行，并更新。或用版本号，更新前检查版本号，更新时version+1.
3)记录并检查：每个msg一个全局唯一id，消费时检查msg是否被处理过，再更新，设置msg为已消费。要求检查、更新、设置是原子的。可以用事务、锁实现。

7.消息积压
producer：并发、批量大小。
consumer：优化消费逻辑；consumer取消息放入内存队列，再多线程处理。会丢消息。批量消费：可批量处理、入库，减少带宽overhead。但需要整体ack，某一消息失败会引起很多重试；多线程批量消费速度为最慢线程。
若发送突然变快：如抢购、大促。扩容consumer实例数。降级关闭不重要业务。若消费变慢：log consumer error；堆栈，是否死锁或卡在某资源。若收发速度不变，是否consumer反复消费同一消息。

12.序列化
可读性；速度；空间。内存中的对象是不通用的，不同系统、语言的组织都可能不同，且有很多引用、指针，并不是直接数据块。所以需要通过序列化，变成标准格式，进而跨平台、跨语言。
对强业务类系统，业务复杂，需求变化快，性能要求不高，用json这种实现简单、可读性好的。
专用实现：不用通用。更高效，字节少，传输快，但是实现复杂。适合性能要求高的场景。

13.传输协议
分隔符：http1:\r\n。 如何区分数据内的分隔符和真正的分隔符：1)先对数据内分隔符转义，收到数据后再转回来。2)固定字节数表示len+数据。
单工通信：http1。client与server建立连接后，client发请求，直到server返回响应或超时，才能发送下一请求。优：请求和响应按顺序依次收发，易对应。效率低：client会建立多个连接。
全双工：tcp。同时双向收发。优：吞吐高。缺：request和response无法对应：req中带本session内唯一的seqid，response也要带响应的seqid。顺序无法保证。

14.内存管理
申请：计算对象要占用的内存大小；在内存中找连续、且空闲的内存空间，标记为已占用；将该内存地址绑定到对象引用。
回收：查找可回收的对象，标记为空闲；整理碎片。mark-sweep：需要暂停进程。
为什么高并发时进程易卡死？服务进程在收到请求后，执行业务逻辑，会创建对象（req、response、业务逻辑要使用的对象等）。当请求结束时，这些对象也无用，但会一直占用内存直到gc。高并发时，短时间创建大量对象，迅速占满内存。gc启动，要回收的对象很多，长时间暂停进程。大量请求积压等待，gc刚结束，更多请求涌入，又占满内存，又gc。若gc速度跟不上创建对象的速度，可能oom。=》减少创建一次性对象，尤其是占用内存大的对象。如Request对象在业务流程中一直传递，而不是每次都创建新Request。对象池。

15.kafka如何高性能
单节点2kw条/s，吞吐600MB/s。
批量处理：producer.send()，不管是同步、还是异步发送，都先缓存再批量发送。broker将批作为整体处理：写磁盘、读磁盘、复制到其他副本。consumer拉一批再交给业务代码处理。
顺序io。
page cache：写文件时，先写pagecache，再批量写磁盘。读文件时，若命中pagecache，直接读；否则缺页中断从磁盘读。故程序用完某pagecache时，不立刻清除，等内存不够时才用LRU等清除。若msg刚写入就被消费，pagecache命中率很高。
0copy：从文件读数据再通过网络发送：先从文件复制到pagecache，若命中pagecache，可省略；从pagecache复制到程序内存；从程序内存复制到socket缓冲区。0copy可将pagecache数据直接DMA复制到socket缓冲区。对应sendfile()系统调用。




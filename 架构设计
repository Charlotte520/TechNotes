1. search
爬虫系统；建立索引、查询索引系统；rank系统。写入和检索分离。
如何两个集合求交集？  for*for：O(n^2)。 =》根据docid排序：O(n)，多个集合可同时求交集。=》并行：将集合分成多个桶区间，每个区间并行求交集再合并结果。=》bitmap：每个桶的数据处于一定范围内，求交集为两bitmap 与操作。=> skiplist: O(logn)
如何快速更新index？index分级，全量库、日增量库、小时增量库。新网页更新到小时库，查询时合并多级别index的结果。异步将小时导出到日，日到全量。

2. 连接池
list<Conn>; list<Lock>;  
init(); 初始化n个conn和lock。
getConn()：遍历找到lock为false的conn。用map可o(1)
freeCoon(c)：找到conn，并释放锁。
conn是否可用，若失效要重新建立；每个conn被取到的概率相同，实现LB；若下游故障，失效conn要剔除，实现故障转移；若有新增，动态扩充conn，实现服务发现。

3. 顺序消息
将同一userid的所有消息都发到同一server上，再串行化：rpc调用方通过RPCClient连接池访问下游服务。ConnPool.getConnection()时，传入userid，取模得到同一conn。

4.协议设计：系统通信
语法：数据、控制信息的结构；语义：发什么控制信息，完成什么动作、如何响应；时序：顺序详细说明。
三层：应用层、安全层、传输层。
应用层：文本（http，可读易debug、可通过kv扩展、解析效率低、对img、vedio等二进制不友好）、二进制（IP，ProtoBuf，定长header、可可扩展变长body、每个字段有固定含义。可读性差、扩展时旧版不兼容，需要version、解析效率高、天然支持二进制流）、流式xml（可读，解析代价高，标签多效率低）。
安全层：ssl。固定密钥：client、server约定密钥和加密算法，client发送前先加密再传，server解密（安全性低）。一人一密：固定加密算法，密钥基于用户属性（uid、phone、psw等）。一次一密：每次session前协商密钥。
传输层：tcp、udp。tcp用epoll可支持几十万conn。

5. 移动app
用ip代替dns连接后端：app第一次访问时，用域名拉ip-list，之后用本地ip-list访问server。增加ip：版本号（减少流量，保证数据随时更新）。
日志上报：server log无法统计所有用户行为。用Google analytics等第三方工具，不能个性化。自定义协议：省流，成本高。http：get参数传要上报的数据（web server下放一文件，app发http请求该文件，分析access log）。http://xx.com/up?[bj][20190304][login]：访问up文件，分隔符为[]，字段含义固定。扩展性差，空字段也要保留占位符。http://xx.com/up?city=bj&date=20190304&action=login：扩展性好，耗流量（无效数据、url、key冗余、频繁）。=》手动构造http请求；短域名；key简短c代替city；本地存储，定时上报，数据压缩。如特殊时间点（app打开、关闭、后台转活跃）；按时间（每隔10min）；按数据量（每10条）。

6. 微服务
rpc：序列化/反、网络框架、连接池、收发线程、超时处理、状态机。
rpc client：
序列化：数据存储/传输时，要将object转为连续空间的二进制字节流（db的b+树索引要转存到磁盘；redis的kv持久化；socket发送的数据）。可用xml/json自描述的标记性语言；二进制协议:seqid,key_len,key,val_len,val_type,val...，嵌套类型等。考虑解析效率；压缩率；扩展性；可读性；跨语言。
同步调用：r=add(a1,a2)。序列化组件、连接池组件（LB、故障转移、发送超时等）。
异步调用：add(a1,a2,callback); callback(r){...} 上下文管理器、下游收发队列、下游收发线程、超时管理器。上下文：对请求包生成id，context(id,time,cb,timeout_cb)，以id为key保存到map中。req、res都带id。超时：timer扫描context map，若超时调用timeout_cb，删除。

7.LB
dns轮询；lvs os层面，f5硬件；nginx（轮询、最少连接、ip hash、weight）；web server到service用conn pool；数据层：请求/数据均衡，可按range（请求不一定均衡）或hash（不易扩展）切分数据。
异构server LB：静态weight；动态weight（conn poll初始给每个server的w=60,每成功处理一个请求，w+1;超时处理w-10,限定范围为[0-100]）
过载保护：server静态设阈值，超出的请求丢弃；动态（成功+1,超时-10），策略：若连续3个请求都timeout，接下来的若干秒不发给它请求，如10s。若w为0，接下来更长时间不发请求，如fullGC的机器等1min。

8. 运维
无损上线：升级重启时，正在访问的用户会失败。若升级web-server，给nginx发指令，将s1上的流量切走，旧流量处理完后升级重启。若升级service，给rpc server发指令，通过tcp长连接通知rpc client，由其conn pool切走，server将旧流量处理完再升级。

9. mysql
主从延时：slave同步master binlog，单线程落盘到relaylog，再单线程重放。=》多线程重放，如何切分relaylog，保证执行顺序和master一致？若多库，可hash(db_name)%#threadNum，不同库并行，同一库串行。=》master上并行执行的事务分为一组，编号GTID，相同last_committed的可并发回放。

10.IM
多点登录：gate（保持与client的连接），cache（userid：online，gateNo）。接收方多点登录时，cache记录(userid_pc: online,gateNo)。发送方多点：消息也要发给发送方其他登录端。
消息漫游：存云端，client存last_msg_id。
离线消息：发送的消息写入db则发送成功。receiver_uid,msgid,time,senderid,msgtype,msgcontent... B上线时根据(receiverid+senderid)查询，返回，ack后，再删除。要获取所有好友的离线消息，要多次请求。=》按需省流量，先拉各好友的msg count，查看时再发请求。=》减少请求次数，根据receiverid查询，本地再根据senderid分组。一次拉取数据包太大：分页，先拉最新，拉取下一页相当于对前一页的ack。
群聊：在线好友立即收消息；离线好友登录后收。群成员表：(groupid,userid)，群消息表(groupid,msgid,senderid,time,content)，群离线消息表(userid,groupid,msgid)，减少msg content冗余。上线后收到消息，删(uid,gid,mid)。=》不要存每条msgid，存(userid,groupid,last_ack_msgid)，拉取之后所有msg。

11. push vs pull
系统通知：实时性要求高，push；登录弹窗，pull，用last_msg_time；批量弹窗，push，限速，或pull，请求均匀分散。
登录状态：push。群友的消息扩散系数太大，进群时按需pull。
网页端消息：http web socket长连接。长轮询：用http短连接拼接长连接，server夯住请求直到有通知到达，或超过阈值（150s）server返回null断开。client发起请求时，若server queue有消息，则实时返回。client收到消息，立刻再发起http请求。若server queue无消息，则等待。若有消息到达，返回消息，再连接。若消息到达时，无连接，则放入queue。
群消息已读回执：消息回执表 msg_acks(sender, msg, receiver, group, if_ack)  server收到发送的消息时，写msg表，插入msg_ack，if_ack为false。接收方修改last_ack_msgid时，修改if_ack，查询sender状态，若在线则push已读消息，否则下次上线时从ack表pull每条消息的已读回执。=》批量ack

12. cache
memcache 快 vs redis 功能多: redis支持hash、list、set等复杂结构；可持久化（定期snapshot不保证数据不丢，AOF会降低效率且数据量不能太大），重启时快速恢复数据而不是从db获取，适合只读或允许不一致的场景；高可用（主从复制，读写分离，sentinel监控主从服务，故障自动转移）；可支持1M以上的value大小。实现：内存（m预分配内存池，r临时申请，可能有碎片）；虚拟内存（m全部物理内存，r用vm支持更多数据，但有可能swap）；网络（都是非阻塞IO复用。r提供非kv存储外的排序、聚合等，复杂cpu计算可能阻塞io）；线程（m多线程，主监听，worker接受请求读写，可能有锁冲突。r单线程，无锁冲突，但无法利用多核）。
不要将cache用作service间传数据（用mq），导致service耦合；不同service要有独立的cache，避免热数据被替换。
cache挂掉/某热点key失效，如何避免db雪崩：db扩容。cache高可用（master-slave）；水平切分（某实例挂掉，不会所有流量都到db）。ReentrantLock(key):抢到锁的线程读db，并写到cache。其他线程读cache。若设置主从cache，要双写。其他线程读从cache，或返回降级的固定内容。也可用ConcurrentHashMap<key,xx>对不同内容加不同锁。
cache穿透：大量访问db不存在的key。=》如何快速知道db中是否有key？bloomfilter。
两级cache：进程内（不一致）；分布式。

13. mysql
实践：存储引擎用innodb；字符集用utf8（通用，无乱码风险，汉字3B，英文1B，utf8mb4用4B存表情符号）;禁用存储过程、view、触发器、event（性能影响大，调试、迁移困难，在service层做）；禁存大文件（db存路径，文件存对象存储系统）；测试、线上db隔离。表必须有primary key（unsigned int），删除无PK的表，从库会挂住。禁止用外键，由app保证完整性（影响update、delete性能，可能死锁）。字段区分char、varchar（长度固定用char减少碎片，相差大或更新少用varchar减少空间）。字段not null并设默认值（null列index困难、存储更多）。index：个数<5；频繁更新的字段不要建index；join字段类型必须相同；最左前缀。select要指定字段（减少cpu、io、带宽消耗，利用索引覆盖）。insert指定字段（变更表结构对程序无影响）。同一字段的or改成in。
index：hash对group by、order by、比较查询会o(n)。b树：叶子、非叶子都存数据，中序遍历得到全部数据，节点大小为页大小（局部性原理、磁盘预读）。b+树：叶子存数据，非叶子只存key，内存可存更多索引，不需要中序遍历可得所有数据。myisam：index和row分开存储，unclustered，表可以无pk。pk index
的叶子存pk和row指针，普通index的叶子存索引列和row指针。innodb：clustered index，pk index和row存在一起。表必须有唯一的clustered index，为pk或第一个非空unique index或隐藏rowid。cluster index的叶子存数据行，普通index的叶子存pk，故普通索引要扫两遍。不要用长列做pk；用趋势递增key做pk，减少insert时index分裂移动row。
并发控制：lock &mvcc。普通锁（访问资源加锁，完成后释放），串行，不区分读写 =》共享锁s&排他锁x：读读可并行，读写/写写不并行。=》mvcc：读写可并行。redo log：保证已完成事务的acid。修改先顺序写redo log，再定期将内存数据刷到磁盘，重启后重做redo log，将未刷到磁盘的内容写回。undo log：保证未完成事务不影响acid。未提交时，旧数据放undo log，回滚/崩溃时，根据undo log撤销未提交事务的影响。insert操作，记录pk(row id)，回滚时删除。update/delete，记录旧数据行，回滚时恢复。记录到回滚段中。提交后删除该段的undo log。=》mvcc每行增加txid(最近一次修改行的事务id)，roll_ptr（指向回滚段undolog的指针），row_id。旧数据放入回滚段，可高并发读。
innodb：默认rr，最常用rc。read uncommited级别：select不加锁，可能脏读。RC隔离级别下：普通读为快照读；加锁select、update、delete等，foreign key constraint checking和duplidate key checking要锁区间，其他用record lock，可能幻读。RR隔离级别下：快照读 consistent nonblocking read（普通select语句），（保证事务读到的数据，要么是开始前就已存在数据，要么是本事务自身插入、修改的）。非快照读，select* lock in share mode/ select * for update，update、delete等语句，若在unique index用unique search condition，用record lock；若range-type search condition，用gap lock、next-key lock，避免范围间插入导致的幻读和不可重复读。串行化级别：select隐式转为select in share mode，与update、delete互斥。
myisam vs innodb: m不支持事务，可lock table，不支持foreign key。适合select+insert场景，尾部顺序增加，快。innodb行锁实现在index上，若没有命中index，退化为表锁。
innodb 7种锁：shared&exclusive lock（行级）；intention lock（表级，select lock in share mode设intention shared lock，for update设intention exclusive lock。事务要加s锁，必须先获取is，要获取x锁，必须先获取ix锁。is、ix可并行。is与s可并行，is与x、ix与s不可并行）；record lock；gap lock；next-key lock；insert intention lock（多个事务，在同一个索引、同一范围插入时，若插入位置不冲突不阻塞）；auto-inc lock（表级，若事务a正在对auto-inc的记录insert，其他事务的插入要等待，保证a插入连续pk）。
innodb pk和unique index约束：insert、update时触发。

14. 秒杀 分流+限流
客户端：限制点击次数（button变灰），提示，不发http请求。
服务端：集群分流，负载均衡。用redis：userid/ip+timeout限制同一用户在某段时间内的访问次数。（set(k,v,ex=10s,ifnotpresent))

15. 分布式锁
jvm lock只能在本进程内使用，集群环境下无效。分布式锁：排他性（文件系统）；阻塞性；可重入性。
zk：临时节点，创建节点的进程获得锁，释放时删除节点。其他进程watch该节点，被删除时被唤醒，重新创建。=》惊群效应：临时顺序节点。没有获取锁的进程watch前一节点。
class DistributedLock extends Lock {
        ZKClient client = new ZKClient("ip", "port");        
        @Override
        public boolean tryLock() { //不阻塞
            try {
                client.createEphemeral("path", "data");
            } catch (ZkNodeExistsException e) {
                return false;
            }
            return true;
        }
        
        @Override
        public void lock() {
            if (!tryLock()) {
                waitForLock(); //获取不到时，阻塞等待。获取成功，则递归调用重新获取
                lock();
            }
        }

        private void waitForLock() {
            CountDownLatch cdl = new CountDownLatch(1);
            ZKDataDeleteListener listener = new ZKDataDeleteListener() {
                @Override
                public void onDeleted(String s) {
                    cdl.countDown();
                }
            };
            client.registerDataDelete("path", listener);//1.监听
            if (client.exists("path")) {
                try {
                    cdl.await(); //2.阻塞
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
            client.unregisterDataDelete("path", listener); //3.被唤醒时，取消监听
        }
    }
    
   class DistributedLock2 extends Lock {
        ZKClient client = new ZKClient("ip", "port");
        String parentPath = "/parent";
        String curPath;
        String prevPath;
        public DistributedLock() {
            if (!client.exists(parentPath)) {//预先创建永久父节点
                client.createPersistent(parentPath);
            }
        }
        @Override
        public boolean tryLock() { //不阻塞
            if (curPath == null) {
                curPath = client.createEphemeralSequential(parentPath + "/" + "aaa", "data");
            }
            List<String> children = client.getChildrenNames(parentPath); //获取所有子节点，排序，若本进程是最小节点则获取锁
            Collections.sort(children);
            if (curPath.equals(parentPath + "/" + children.get(0))) {
                return true;
            } else {
                prevPath = parentPath + "/" + children.get(children.size() - 1);
            }
            return false;
        }
        @Override
        public void lock() {
            if (!tryLock()) {
                waitForLock(); //获取不到时，阻塞等待。获取成功，则递归调用重新获取
                lock();
            }
        }

        private void waitForLock() {
            CountDownLatch cdl = new CountDownLatch(1);
            ZKDataDeleteListener listener = new ZKDataDeleteListener() {
                @Override
                public void onDeleted(String s) {
                    cdl.countDown();
                }
            };

            client.registerDataDelete(prevPath, listener);//1.监听
            if (client.exists(prevPath)) {
                try {
                    cdl.await(); //2.阻塞
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
            client.unregisterDataDelete(prevPath, listener); //3.被唤醒时，取消监听
        }
    }
